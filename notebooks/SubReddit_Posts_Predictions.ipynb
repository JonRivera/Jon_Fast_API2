{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from seaborn) (1.19.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from seaborn) (3.3.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from seaborn) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: basilica in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (0.2.8)\r\n",
      "Requirement already satisfied: Pillow in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from basilica) (7.2.0)\r\n",
      "Requirement already satisfied: requests in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from basilica) (2.24.0)\r\n",
      "Requirement already satisfied: six in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from basilica) (1.15.0)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from requests->basilica) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from requests->basilica) (2020.6.20)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from requests->basilica) (2.10)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from requests->basilica) (1.25.10)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\r\n",
      "You should consider upgrading via the '/Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: scikit-learn in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (0.23.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (from scikit-learn) (1.19.1)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\r\n",
      "You should consider upgrading via the '/Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "pip install basilica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in /Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/lib/python3.8/site-packages (1.3.19)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/Users/johnrivera/.virtualenvs/Post_Subreddits-R7WzUq5X/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SQLAlchemy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import basilica\n",
    "import decouple\n",
    "import numpy as np\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rspct.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1013000 entries, 0 to 1012999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   id         1013000 non-null  object\n",
      " 1   subreddit  1013000 non-null  object\n",
      " 2   title      1013000 non-null  object\n",
      " 3   selftext   1013000 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 30.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seperate Data Frame into Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features = ['id','selftext','subreddit']\n",
    "target = ['subreddit']\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train, y_test = train_test_split(X,y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810400"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810400"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#want to predict what subreddit a randomtext is more likeley to belong to\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#reduce number of rows to 100; truncation\n",
    "X_new = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_new = X_new.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654626</th>\n",
       "      <td>60dwoc</td>\n",
       "      <td>I would love to hear your experience with the ...</td>\n",
       "      <td>slp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630792</th>\n",
       "      <td>7bvasp</td>\n",
       "      <td>Hi all,&lt;lb&gt;&lt;lb&gt;Looking to see if anyone recogn...</td>\n",
       "      <td>whatsthisplant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934315</th>\n",
       "      <td>56tts7</td>\n",
       "      <td>Hello. I'm a posdoc in the computer science de...</td>\n",
       "      <td>bioinformatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509697</th>\n",
       "      <td>5fv11j</td>\n",
       "      <td>Hey Guys, &lt;lb&gt;&lt;lb&gt;So currently in a situation ...</td>\n",
       "      <td>sharepoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451723</th>\n",
       "      <td>7op7n3</td>\n",
       "      <td>I feel like a crazy person with thoughts pouri...</td>\n",
       "      <td>Stellar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           selftext       subreddit\n",
       "654626  60dwoc  I would love to hear your experience with the ...             slp\n",
       "630792  7bvasp  Hi all,<lb><lb>Looking to see if anyone recogn...  whatsthisplant\n",
       "934315  56tts7  Hello. I'm a posdoc in the computer science de...  bioinformatics\n",
       "509697  5fv11j  Hey Guys, <lb><lb>So currently in a situation ...      sharepoint\n",
       "451723  7op7n3  I feel like a crazy person with thoughts pouri...         Stellar"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_new['text_encoded'] = np.arange(len(X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I would love to hear your experience with the district as I'm considering applying for the 2017/18 school year. The salary is certainly quite a draw; they seem to pay significantly more than other districts in the area. Is there a particular reason for this? High caseloads, etc.? Any and all information is appreciated. Thanks in advance! \n",
      "\n",
      "\n",
      "Hi all,<lb><lb>Looking to see if anyone recognizes [this place](https://i.imgur.com/sgXVTdM.png). It's a view of a garden in behind what I assume is a restaurant or bistro. A professor traveled here and the only thing he mentioned is that he had one of the best meals of his life here.<lb><lb>I was hoping that if someone in this community could identify any of the plants in this image it would help me narrow down where the picture was taken. The lighting in the picture is horrible but it's all I have to work with.<lb><lb>I don't even know what country it is in, but if I had to take an educated guess I would assume it is South America somewhere as that is where most of his research takes place. Sorry I can't provide more information, that is all I was told.<lb><lb>Cheers!\n",
      "\n",
      "\n",
      "Hello. I'm a posdoc in the computer science department in Mato Grosso do Sul, Brasil. I'm preparing two presentations, from 2 to 3 hours for students finishing school here (the year before entering a university, i think its different depending on the country we speak, the name we give to this year os school). The idea is to show something about bioinformatics, and how it is part of our life, and that it can be fun too.<lb>I thought about one presentation about human paternity test, since its part of our daily life, and another one about phylogeny.<lb><lb><lb>The cool part of paternity test, is that i can show some example of real results, they are common on television, there is a relativity simple statistics involved to show examples and there are real data on the paternity test results to show.<lb><lb>Now about phylogeny, i have some possibilities in my mind, but does anyone have a cool example dataset, maybe of beautiful species, which i could gather photos, or maybe of how phylogenies helped solve some problem, but it is important to have a data set, an easy one, 16s mdna, don't know, to show the students, make them do calculations on a online tools, maybe make one, maybe just the references for genbank so they can download the data.<lb><lb>Well, that it, if anyone give ideias of cool examples, things that maybe can be eyecandy for students that have no ideia about bioinformatics, molecular biology, nothing but what they learn from biology classes. Thats it, thanks for the attention and i can share the results here, if someone want to use it too. I'll probably make a html with the exercises, and probably make the tools to be used embedded in the page, to make everything really easy.\n",
      "\n",
      "\n",
      "Hey Guys, <lb><lb>So currently in a situation where our client has the employees birthday field coming into SharePoint On-Prem via a custom field property (this is mapped to the birthdays field in SharePoint already). I now have to get this setup going for SharePoint Online however you are unable to map a custom field (in AD) to a property in UPS (User Profile Services) online thus have to use a PowerShell script. <lb><lb>Iv got the done for one person already and working but now I need to find a way to export all the employees and the birthday field from on-prem to a CSV/other equivalent and then add this to my Powershell to run once a month. <lb><lb>Any ideas or guidelines would be awesome.\n",
      "\n",
      "\n",
      "I feel like a crazy person with thoughts pouring in. <lb><lb>If a large grocery store decided to use the stellar exchange to make direct payments to vendors whom are trusted sources the banks and even ripple could do nothing to stop it. <lb><lb>Then any business with trusted vendors could use the exchange to pay without incurring the fees, saving both the retailer side and supply side huge banking fees. <lb><lb>Even at 100 USD lumen meaning .10 cent transactions fees, Walmart could pay 1000 vendors, using 1 lumen to cover the fees. <lb><lb>It is revolutionary thinking to cut the bank fees out of the equation, while ripple is putting it's trust in the banking system. <lb><lb>Sorry, late night rambling!<lb><lb>\n",
      "\n",
      "\n",
      "Hey,<lb><lb>I'm looking for films that have shot in the 1.66:1 aspect ratio. If you know of any or can point me in the direction of a list that would be great.<lb><lb>I know Kubrick shot in that aspect ratio, but all the films that he shot in that way are shown at 1.77 or 1.85. Well, the ones I've seen anyway.<lb><lb>If you know of any music videos or related that shot in that ratio, that would be appreciated also.<lb><lb>EDIT: Just our of curiosity also, does anyone know of any films/videos that were shot in an aspect ratio similar to that of a full frame camera?<lb><lb>Cheers!\n",
      "\n",
      "\n",
      "No spoilers<lb><lb><lb>If it’s anything like the leaked script I’m probably going to walk out, not going to ruin anything for anyone but holy shit that was a bigger disappointment then when I went to the Star Wars ep7 midnight showing and some kid screamed out that Han gets killed(kid and his family got kicked out and no refund) <lb><lb><lb>Also why the hell did they just not make it a trilogy the book was set up perfectly for a trilogy \n",
      "\n",
      "\n",
      "I'm willing to pay a decent resale price, though does anybody know if more tickets will ever be on sale again? <lb><lb>I have 2 friends who want to come with me but they were too late to buy tickets.<lb><lb>EDIT: No luck yet, I've emailed people and refreshed the ticket website so much that my hand hurts.\n",
      "\n",
      "\n",
      "Hey guys, <lb><lb>I’ve got a few questions about what we are supposed to do as tech sales associates because I can’t help but feel like I’m getting screwed over here.<lb><lb>Basically, I feel like I do more than what I’m supposed to be doing. Maybe I’m wrong but essentially, my managers have me; sell, stock, make sure product security is perfect, make sure the floor looks good, etc. All that is fine and what I’d expect to have to do. But now I also have to change planograms, do cycle counts, clean the entire locker every week(gets messy because the person unloading truck puts most of the stock in there), help customers in office supplies because we only have 1 aisles associate for the entire store. Also, since nobody wants to get off their high horse and help stock, or help with removing tags and sale signs, I have to do about 80% of the stocking and signs for the entire tech. No one likes to task, only sell, yet I still have the highest sales numbers, highest asp, ecp%, etc...<lb><lb>Worst of all, we are always short staffed in tech because of turnover, punctuality problems, people just calling in sick, and managers lack of urgency to hire people so I constantly find myself helping 4 or 5 customers at a time while my MOD only handles 1 at a time for 20mins. <lb><lb>All the while I get paid minimum wage, no bonus(yet?) and While everyone has some control over their schedule, I have none and have to work every garbage shift possible. Losing morale. Its been 8 months and I honestly don’t know why I’m still working at staples.<lb><lb>Anyways I’m just wondering what you guys have to do or if you guys have to do even more s**t.<lb>\n",
      "\n",
      "\n",
      "I have just started casting and so far my few color designs have come out much better than anything I have previously purchased except one specific type of design.<lb><lb>I do not know how to make thin colored lines.  Like for example, you have a red blank, I want white \"swirls\" and lines but nice and thin going through the entire blank not mixed in the other main color, but looking like lines dropped in.  [This](http://www.rockler.com/lollipop-acrylic-acetate-pen-blank) is an example of what I mean.<lb><lb>This stuff is expensive so I am asking before I just go \"test\" and potentially waste a lot of acrylic. I have looked on youtube but all I see are guys doing the standard dump of two or more colors and swirling with a stick which just produces a jumble mix of color.<lb><lb>any suggestions?<lb><lb><lb><lb><lb>\n"
     ]
    }
   ],
   "source": [
    "for x in X_new['selftext']:\n",
    "    print()\n",
    "    print()\n",
    "    print(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Make Embeddings from SQL Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BASILICA_KEY =\"92d11023-f16d-00d3-92c6-4fd80a32fdc3\"\n",
    "BASILICA = basilica.Connection(BASILICA_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#embed all the posts into basillica embeddings\n",
    "all_post_embeddings = []\n",
    "for text in df['selftext'].iloc[:10]:\n",
    "    embedding = BASILICA.embed_sentence(text, model='reddit')\n",
    "    all_post_embeddings.append([np.array(embedding)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_post_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# I want to get the embeddings from my sqllite data base as appose to the data frame\n",
    "# Also i want to get the selftext from the sql data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make a connection with data base to acces data\n",
    "conn = sqlite3.connect('Subreddits.db')\n",
    "c = conn.cursor()\n",
    "query ='SELECT selftext FROM SUBREDDITS LIMIT 10;'\n",
    "#change the limit to 10 for fast execution of code\n",
    "c.execute(query)\n",
    "selftext = c.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Subreddits.db')\n",
    "c = conn.cursor()\n",
    "query2 ='SELECT subreddit FROM SUBREDDITS LIMIT 10;'\n",
    "#change the limit to 10 for fast execution of code\n",
    "c.execute(query2)\n",
    "subreditts = c.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talesfromtechsupport',),\n",
       " ('teenmom',),\n",
       " ('Harley',),\n",
       " ('ringdoorbell',),\n",
       " ('intel',),\n",
       " ('residentevil',),\n",
       " ('BATProject',),\n",
       " ('hockeyplayers',),\n",
       " ('asmr',),\n",
       " ('rawdenim',)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreditts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subreditts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedded_selftext = []\n",
    "for x in results:\n",
    "    text = list(x)[0]\n",
    "    embedding = BASILICA.embed_sentence(text, model='reddit')\n",
    "    embedded_selftext.append(np.array(embedding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subreddits_from_data_base = []\n",
    "for x in subreditts:\n",
    "    text = list(x)[0]\n",
    "    subreddits_from_data_base.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subreddits_from_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_selftext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Making Embeddings from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#create a list with numpy arrays of embeddings\n",
    "#not sure whether it matters whether the embeddings are in numpy array format or in list\n",
    "#format for the creation of the model\n",
    "list1 = []\n",
    "for text in X_new['selftext']:\n",
    "    embedding = BASILICA.embed_sentence(text, model='reddit')\n",
    "    list1.append(np.array(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2 = [name for name in X_new['subreddit']]\n",
    "len(labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Constructing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Relied from data extracted from pandas data frame\n",
    "log_reg = LogisticRegression(max_iter=1000).fit(list1, labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Relied on Data from SQLLITE DATA BASE *\n",
    "log_reg2 = LogisticRegression(max_iter=1000).fit(embedded_selftext,subreddits_from_data_base,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models Into PickleFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = open('logistic.dummy','wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(log_reg2,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reg_file = open('logistic.dummy','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = pickle.load(reg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LinearClassifierMixin.predict of LogisticRegression(max_iter=1000)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reddit_embedding = BASILICA.embed_sentence(\"I would love to hear your experience with the district as I'm considering applying for the 2017/18 school year. The salary is certainly quite a draw; they seem to pay significantly more than other districts in the area. Is there a particular reason for this? High caseloads, etc.? Any and all information is appreciated. Thanks in advance! \", model='reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reddit_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['intel'], dtype='<U20')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1 = log_reg.predict(np.array(reddit_embedding).reshape(1, -1))\n",
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['intel'], dtype='<U20')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2 = log_reg2.predict(np.array(reddit_embedding).reshape(1, -1))\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['intel'], dtype='<U20')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(np.array(reddit_embedding).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intel'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intel'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
